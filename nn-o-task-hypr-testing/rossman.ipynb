{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelReg(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim):\n",
    "        super(ModelReg, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.input_dim + 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim + 10, self.input_dim + 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim + 10, self.input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim, self.input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim // 2, self.output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRegv2(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ModelRegv2, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.input_dim * 2 + 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.input_dim * 2 + 2, self.input_dim + 1),  # Исправлено\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.input_dim + 1),  # Исправлено\n",
    "            nn.Linear(self.input_dim + 1, (self.input_dim + 1) // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear((self.input_dim + 1) // 2, self.output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRegv4(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ModelRegv4, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.input_dim * 2),  # 31 -> 62\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.input_dim * 2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.input_dim * 2, self.input_dim),  # 62 -> 31\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.input_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.input_dim, self.input_dim // 2),  # 31 -> 15\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim // 2, self.output_dim)  # 15 -> 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRegv3(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ModelRegv3, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.input_dim * 3),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim * 3, self.input_dim * 2),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim * 2, self.input_dim + 32),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Dropout перед уменьшением размерности\n",
    "            nn.Linear(self.input_dim + 32, self.input_dim // 2 + 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim // 2 + 16, self.input_dim // 4 + 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.input_dim // 4 + 8, self.output_dim)  # Выходной слой\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#data\n",
    "store_df = pd.read_csv('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/rossman/store.csv')\n",
    "train_df = pd.read_csv('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/rossman/train.csv')\n",
    "\n",
    "store_df['CompetitionDistance']= store_df['CompetitionDistance'].fillna(store_df['CompetitionDistance'].median())\n",
    "store_df['CompetitionOpenSinceMonth'] = store_df['CompetitionOpenSinceMonth'].fillna(0)\n",
    "store_df['CompetitionOpenSinceYear'] = store_df['CompetitionOpenSinceYear'].fillna(0)\n",
    "store_df['HasCompetition'] = store_df['CompetitionOpenSinceMonth'] != 0\n",
    "store_df['Promo2SinceWeek'] = store_df['Promo2SinceWeek'].fillna(0)\n",
    "store_df['Promo2SinceYear'] = store_df['Promo2SinceYear'].fillna(0)\n",
    "store_df['PromoInterval'] = store_df['PromoInterval'].fillna('None')\n",
    "\n",
    "store_df = pd.get_dummies(store_df, columns=['StoreType', 'Assortment', 'PromoInterval'], prefix = ['StoreType', 'Assortment', 'PromoInterval'], dtype=int)\n",
    "store_df['HasCompetition'] = store_df['HasCompetition'].astype(int)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (20,20))\n",
    "sns.heatmap(store_df.corr(), ax = ax, annot=True)\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/store_df_corr.png')\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (20,20))\n",
    "sns.heatmap(train_df.corr(numeric_only=True), ax = ax, annot=True)\n",
    "\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/train_df_corr.png')\n",
    "\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "train_df = train_df.sort_values(by='Date')\n",
    "train_df['StateHoliday'] = train_df['StateHoliday'].astype(str)\n",
    "train_df = pd.get_dummies(train_df, columns=['StateHoliday'], prefix=['StateHoliday'], dtype=int)\n",
    "\n",
    "train_df['Year'] = train_df['Date'].dt.year.astype('int64')\n",
    "train_df['Month'] = train_df['Date'].dt.month.astype('int64')\n",
    "train_df['Day'] = train_df['Date'].dt.day.astype('int64')\n",
    "\n",
    "merged_df = pd.merge(train_df, store_df, on='Store', how='left')\n",
    "\n",
    "#EDA\n",
    "\n",
    "fig,ax = plt.subplots(figsize = (40,20))\n",
    "sns.heatmap(merged_df.corr(), ax = ax, annot=True)\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/merged_df_corr.png')\n",
    "\n",
    "# Sales\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(merged_df['Sales'], kde=True)\n",
    "plt.title(' Sales distribution')\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/Sales_distribution.png')\n",
    "\n",
    "merged_df.set_index('Date', inplace=True)\n",
    "plt.figure(figsize=(14, 6))\n",
    "merged_df['Sales'].resample('W').sum().plot()\n",
    "plt.title('Sales by week')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Sales')\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/Sales_by_week.png')\n",
    "\n",
    "train_df = train_df.drop('Date', axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Promo', y='Sales', data=merged_df)\n",
    "plt.title('Impact of Promo on Sales')\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/Promo_on_Sales.png')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='DayOfWeek', y='Sales', data=merged_df.reset_index())\n",
    "plt.title('The Impact of Day of the Week on Sales')\n",
    "plt.savefig('/home/ir739wb/ilyarekun/nn-lessons/nn-o-task-hypr-testing/results/Day_on_Sales.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "length = merged_df.shape[0]\n",
    "train_len = int(length * 0.7)\n",
    "test_len = int(length * 0.15)\n",
    "val_len = length - train_len - test_len\n",
    "\n",
    "print(length - train_len - test_len - val_len)\n",
    "\n",
    "train_df = merged_df.iloc[0:train_len]\n",
    "test_df = merged_df.iloc[train_len:train_len + test_len]\n",
    "val_df = merged_df.iloc[train_len + test_len:]\n",
    "print(f'train_df {train_df.shape}\\ntest_df {test_df.shape}\\nval_df {val_df.shape}')\n",
    "\n",
    "y_train = train_df['Sales']\n",
    "X_train = train_df.drop('Sales', axis=1)\n",
    "y_test = test_df['Sales']\n",
    "X_test = test_df.drop('Sales', axis=1)\n",
    "y_val = val_df['Sales']\n",
    "X_val = val_df.drop('Sales', axis=1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train.to_numpy(),dtype=torch.float32).reshape(-1,1)\n",
    "y_test = torch.tensor(y_test.to_numpy(),dtype=torch.float32).reshape(-1,1)\n",
    "y_val = torch.tensor(y_val.to_numpy(),dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(X_train.numpy()).sum(), np.isinf(X_train.numpy()).sum())\n",
    "print(np.isnan(y_train.numpy()).sum(), np.isinf(y_train.numpy()).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop 1\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "max_epochs = 100\n",
    "learning_rate = 0.01\n",
    "model = ModelRegv2(31, 1)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam лучше для устойчивости\n",
    "\n",
    "# Metrics\n",
    "train_loss_metr = []\n",
    "val_loss_metr = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0)  # Суммируем loss для всех данных\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)  # Усредняем loss\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item() * data.size(0)  # Суммируем loss для всех данных\n",
    "            \n",
    "        val_loss /= len(val_loader.dataset)  # Усредняем loss\n",
    "    \n",
    "    # Запись метрик\n",
    "    train_loss_metr.append(train_loss)\n",
    "    val_loss_metr.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(train_loss_metr) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss_metr, label='Train Loss', marker='o')\n",
    "plt.plot(epochs, val_loss_metr, label='Validation Loss', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('./nn-o-task-hypr-testing/results/loss_over_epochsv4.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
